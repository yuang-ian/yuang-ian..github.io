<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yuang Shi</title>
  
  <meta name="author" content="Yuang Shi">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yuang Shi (ÊñΩÂÆáÊòÇ)</name>
              </p>
              <p style="text-align:justify">
                I'm a second year Ph.D. Candidate at <a href="https://www.nus.edu.sg">National University of Singapore</a> advised by <a href="https://www.comp.nus.edu.sg/cs/people/ooiwt/">Prof. Wei Tsang Ooi</a>, where I work on Networking and Multimedia Systems.
              </p>
              <p style="text-align:justify">
                I received my M.Comp Degree in 2022 from <a href="https://www.nus.edu.sg">National University of Singapore</a>, where I did research on human activity recognition in-the-wild. I received my B. Eng. Degree in 2021 from <a href="https://en.wikipedia.org/wiki/Sichuan_University">Sichuan University</a> in China, where I worked on Medical Image Processing.
              </p>
              <p style="text-align:justify">
                I'm also a super cat lover. 
              </p>
              <p style="text-align:center">
                <a href="mailto:yuangshi@u.nus.edu">Email</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=ytwibHUAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/Shiyuang-scu">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/SHIyuang.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/SHIyuang_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        <ul></ul>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>News</heading>
                <p>
                  <ul>
                    <li>
                      [01/2024] - One paper (QV4) accepted to MMSys 2024.
                    </li>
                    <li>
                      [12/2023] - Invited <a href="https://dcs.site.nthu.edu.tw/p/406-1174-260551,r67.php" target="_blank">talk</a> at National Tsing Hua University, Taiwan.
                    </li>
                    <li>
                      [12/2023] - Passed my PhD Qualification Exam.
                    </li>
                  </ul>
              </td>
            </tr>
          </tbody>
        </table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Research</heading>
                <p>
                  As a PhD student, I mainly focus on volumetric video compression, evaluation, and streaming.
              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/mmsys24.png" alt="clean-usnob" width="160" height="100">
              </td>
              <td width="75%" valign="middle">
                <a >
                  <papertitle>QV4: QoE-based Viewpoint-Aware V-PCC-encoded Volumetric Video</papertitle>
                </a>
                <br>
                <strong>Yuang Shi</strong>, Bennett Clement, Wei Tsang Ooi
                <br>
                <em>Proceedings of the 15th ACM Multimedia Systems Conference. </em>ACM, 2024.
                <br>
                <!-- <a href="" target="_blank">Paper</a> / -->
                <!-- <a href="" target="_blank">Slides</a> -->
                <p>We present QV4, a Quality-of-Experience (QoE) based streaming system for viewpoint-aware V-PCC-encoded volumetric video. It is the first volumetric video streaming system that exploits user viewing adaptations on V-PCC-encoded content.</p>
                <br><br>
              </td>
            </tr>

            <!-- <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/QE_presentation.png" alt="clean-usnob" width="160" height="100">
              </td>
              <td width="75%" valign="middle">
                <a >
                  <papertitle>Human-Centric Bandwidth-Efficient Volumetric Video Streaming</papertitle>
                </a>
                <br>
                <strong>Yuang Shi</strong>
                <br>
                <em>Qualification Exam Presentation. </em>Oct 2023.
                <br>
                <a href="https://raw.githubusercontent.com/yuang-ian/yuang-ian.github.io/main/images/PhD_QE_Presentation.pdf" target="_blank">PDF (6 MB without video demo)</a> /
                <a href="https://docs.google.com/presentation/d/1b64MB1p5muSJSB1uoDX7f6-6ZB47-mR6/edit?usp=sharing&ouid=116756645024351581996&rtpof=true&sd=true" target="_blank">PowerPoint (150 MB)</a>
                <p>This is my QE presentation, where I introduced the existing challenges and opportunities, and my contributions, ongoing works, and future plan in volumetric video streaming.</p>
                <br><br>
              </td>
            </tr> -->

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/mmsys23_teaser_ref.png" alt="clean-usnob" width="160" height="100">
              </td>
              <td width="75%" valign="middle">
                <a href="https://dl.acm.org/doi/abs/10.1145/3587819.3590981">
                  <papertitle>Enabling Low Bit-Rate MPEG V-PCC-encoded Volumetric Video Streaming with 3D Sub-sampling</papertitle>
                </a>
                <br>
                <strong>Yuang Shi</strong>, Pranav Venkatram, Yifan Ding, Wei Tsang Ooi
                <br>
                <em>Proceedings of the 14th ACM Multimedia Systems Conference. </em>ACM, 2023.
                <br>
                <a href="https://dl.acm.org/doi/abs/10.1145/3587819.3590981">Paper</a> 
                <p>We show that it is possible to improve the quality of V-PCC encoded point clouds at low bit-rate by exploiting redundant information among the points in the 3D domain.</p>
                <br><br>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/mmsys23_dataset.png" alt="clean-usnob" width="160" height="100">
              </td>
              <td width="75%" valign="middle">
                <a href="https://dl.acm.org/doi/abs/10.1145/3587819.3592546">
                  <papertitle>A Dynamic 3D Point Cloud Dataset for Immersive Applications</papertitle>
                </a>
                <br>
                Yuan-Chun Sun, I-Chun Huang, <strong>Yuang Shi</strong>, Wei Tsang Ooi, Chun-Ying Huang, Cheng-Hsin Hsu
                <br>
                <em>Proceedings of the 14th ACM Multimedia Systems Conference. </em>ACM, 2023.
                <br>
                <a href="https://dl.acm.org/doi/abs/10.1145/3587819.3592546">Paper</a> 
                <p>We present an open dynamic 3D point cloud dataset with motion ground truth, which can be used by researchers who need temporal information across frames, e.g., motion estimation.</p>
                <br><br>
              </td>
            </tr>	

          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <p>
                  When I was a Master student, my dissertation is about human activity recognition in-the-wild. 
              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/shapecnf_architecture.png" alt="clean-usnob" width="160" height="70">
              </td>
              <td width="75%" valign="middle">
                <a href="https://ieeexplore.ieee.org/document/9767353">
                  <papertitle>Shape-Based Conditional Neural Field for Wrist-Worn Change-Point Detection</papertitle>
                </a>
                <br>
                <strong>Yuang Shi</strong>, Varsha Suresh, Wei Tsang Ooi
                <br>
                <em>2022 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops). </em>IEEE, 2022.
                <br>
                <a href="https://drive.google.com/file/d/1cDNLQkChUhzaJeazOrpSmHLusLIt5JVz/view?usp=sharing">Paper</a> /
                <a href="https://github.com/Shiyuang-scu/ShapeCNF">Code</a>
                <p>ShapeCNF is a simple, fast, and accurate change-point detection method which uses shape-based features to model the patterns and a conditional neural field to model the temporal correlations among the time regions.</p>
                <br><br>
              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <p>
                  During my undergraduate, I spent most of my time on medical image analysis.
              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/npc_seg.png" alt="clean-usnob" width="160" height="110">
              </td>
              <td width="75%" valign="middle">
                <a href="https://doi.org/10.1016/j.knosys.2023.110598">
                  <papertitle>Uncertainty-weighted and Relation-driven Consistency Training for Semi-supervised Head-and-Neck Tumor Segmentation</papertitle>
                </a>
                <br>
                <strong>Yuang Shi</strong>, et al.
                <br>
                <em>Knowledge-based Systems </em> (2023): 110598.
                <br>
                <a href="https://doi.org/10.1016/j.knosys.2023.110598">paper</a> 
                <p>We propose a consistency training framework for semi-supervised NPC segmentation, which includes an Uncertainty-weighted Prediction Consistency Training (UPCT) strategy and a Relation-driven Consistency Training (RCT) strategy.</p>
                <br><br>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/ASMFS.png" alt="clean-usnob" width="160" height="100">
              </td>
              <td width="75%" valign="middle">
                <a href="https://doi.org/10.1016/j.patcog.2022.108566">
                  <papertitle>ASMFS: Adaptive-Similarity-based Multi-modality Feature Selection for Classification of Alzheimer's Disease</papertitle>
                </a>
                <br>
                <strong>Yuang Shi</strong>, et al.
                <br>
                <em>Pattern Recognition </em>126 (2022): 108566.
                <br>
                <a href="https://drive.google.com/file/d/1hG1PZC4ZAqyZw0hJRDqGrzqBxcDhVTHz/view?usp=sharing">Paper</a> /
                <a href="https://github.com/Shiyuang-scu/ASMFS">Code</a>
                <p>ASMFS is a novel multi-modal feature selection method for classification of Alzheumer's Disease, which performs adaptive similarity learning and feature selection simultaneously.</p>
                <br><br>
              </td>
            </tr>
          </tbody>
        </table>

				
					

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Teaching</heading>
                <p>
                  <ul>                  
                    <li> 
                      [2024/01-2024/05] - Graduate Tutor & Teaching Assistant, CS3244 Machine Learning. 
                    </li>
                    <li>
                      [2023/01-2023/05] - Graduate Tutor & Teaching Assistant, CS3244 Machine Learning.
                    </li>
                    <li>
                      [2022/08-2022/12] - Graduate Tutor & Teaching Assistant, CS3244 Machine Learning.
                    </li>
                  </ul>
              </td>
            </tr>
          </tbody>
        </table>

          <!-- <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/photograph.jpg" alt="photo" width="160" height="120">
            </td>
            <td width="75%" valign="center">
              I love photography. Have a look at some of my <a href="https://flic.kr/ps/3WM9SL"> photos</a>
              <br><br>
            </td>
          </tr> -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Peer Reviewer</heading>
              <p>
                <ul>
                  <li>
                    ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM).
                  </li>
                  <li>
                    IEEE Transactions on Cognitive and Developmental Systems (TCDS).
                  </li>
                </ul>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Volunteer</heading>
              <p>
                <ul>
                  <li>
                    [2023/07] - Student Volunteer, The 14th ACM Multimedia Systems Conference, 2023. With SIGMM Student Travel Award.
                  </li>
                  <li>
                    [2022/11] - Student Volunteer, The 21st IEEE International Symposium on Mixed and Augmented Reality, 2022.
                  </li>
                </ul>
            </td>
          </tr>
        </tbody></table>


        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                This template comes from Jon Barron's public academic <a href="https://jonbarron.info/">website</a>. ‚ù§Ô∏è
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
